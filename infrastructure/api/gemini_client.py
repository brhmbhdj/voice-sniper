"""
Client pour l'API Gemini (Google AI) avec dÃ©couverte dynamique des modÃ¨les.
ImplÃ©mente le port LLMProvider dÃ©fini dans le domaine.
Utilise le pattern "Dynamic Discovery" pour Ã©viter les erreurs 404.
"""

import re
from typing import Optional

import google.generativeai as genai

from domain.models import Prospect, Trigger, Script, Language
from domain.ports import LLMProvider
from infrastructure.config import obtenir_configuration


class GeminiClient(LLMProvider):
    """
    Adaptateur pour le modÃ¨le de langage Gemini de Google.
    ImplÃ©mente une dÃ©couverte dynamique des modÃ¨les pour Ã©viter les erreurs 404.
    """

    def __init__(
        self,
        cle_api: Optional[str] = None,
        nom_modele: Optional[str] = None
    ):
        """
        Initialise le client Gemini avec configuration minimale.
        Le modÃ¨le n'est pas configurÃ© ici (lazy loading).
        
        Args:
            cle_api: ClÃ© API Gemini (si None, utilise la config)
            nom_modele: Nom du modÃ¨le prÃ©fÃ©rÃ© (si None, utilise la config)
        """
        config = obtenir_configuration()
        self.cle_api = cle_api or config.gemini_cle_api
        self.nom_modele_preference = nom_modele or config.gemini_modele
        
        # Configuration de l'API Gemini (sans modÃ¨le spÃ©cifique)
        genai.configure(api_key=self.cle_api)
        
        # Le modÃ¨le sera initialisÃ© Ã  la demande (lazy loading)
        self._modele: Optional[genai.GenerativeModel] = None
        self._nom_modele_effectif: Optional[str] = None
        
        # Configuration de la gÃ©nÃ©ration (indÃ©pendante du modÃ¨le)
        self.config_generation = {
            "temperature": 0.7,
            "top_p": 0.95,
            "top_k": 40,
            "max_output_tokens": 2048,
        }

    def _get_model(self) -> genai.GenerativeModel:
        """
        Lazy loading du modÃ¨le Gemini avec dÃ©couverte dynamique.
        Si le modÃ¨le n'est pas encore initialisÃ©, tente de le dÃ©couvrir automatiquement.
        
        Returns:
            Instance de GenerativeModel prÃªte Ã  l'emploi
            
        Raises:
            Exception: Si aucun modÃ¨le ne peut Ãªtre trouvÃ©
        """
        # Si dÃ©jÃ  initialisÃ©, retourne le modÃ¨le en cache
        if self._modele is not None:
            return self._modele
        
        print(f"ðŸ¤– Initialisation dynamique du modÃ¨le Gemini...")
        print(f"   PrÃ©fÃ©rence utilisateur : {self.nom_modele_preference}")
        
        # Ã‰tape 1 : Essayer le modÃ¨le prÃ©fÃ©rÃ© (s'il est spÃ©cifiÃ©)
        if self.nom_modele_preference:
            try:
                print(f"   Tentative avec : {self.nom_modele_preference}")
                modele = genai.GenerativeModel(self.nom_modele_preference)
                # Test rapide pour vÃ©rifier que le modÃ¨le existe
                modele._model_id  # AccÃ¨de Ã  l'ID pour valider
                self._modele = modele
                self._nom_modele_effectif = self.nom_modele_preference
                print(f"âœ… ModÃ¨le '{self._nom_modele_effectif}' chargÃ© avec succÃ¨s")
                return self._modele
            except Exception as erreur:
                print(f"   âš ï¸  Ã‰chec avec '{self.nom_modele_preference}' : {str(erreur)[:100]}")
        
        # Ã‰tape 2 : Liste des noms Ã  tester (ordre de prÃ©fÃ©rence)
        candidats_a_tester = [
            "gemini-1.5-flash-latest",
            "gemini-1.5-flash",
            "gemini-1.5-flash-001",
            "gemini-1.5-pro-latest",
            "gemini-1.5-pro",
            "gemini-1.5-pro-001",
            "gemini-1.0-pro-latest",
            "gemini-1.0-pro",
            "gemini-pro",
        ]
        
        for nom_candidat in candidats_a_tester:
            if nom_candidat == self.nom_modele_preference:
                continue  # DÃ©jÃ  testÃ© ci-dessus
            try:
                print(f"   Tentative avec : {nom_candidat}")
                modele = genai.GenerativeModel(nom_candidat)
                modele._model_id  # Validation
                self._modele = modele
                self._nom_modele_effectif = nom_candidat
                print(f"âœ… ModÃ¨le '{self._nom_modele_effectif}' chargÃ© avec succÃ¨s")
                return self._modele
            except Exception:
                continue  # Essayer le suivant
        
        # Ã‰tape 3 : DÃ©couverte dynamique via l'API
        print(f"   ðŸ” DÃ©couverte dynamique via list_models()...")
        try:
            modele_trouve = self._decouvrir_modele_dynamiquement()
            if modele_trouve:
                self._modele = modele_trouve
                print(f"âœ… ModÃ¨le dÃ©couvert dynamiquement : '{self._nom_modele_effectif}'")
                return self._modele
        except Exception as erreur:
            print(f"   âŒ Ã‰chec de la dÃ©couverte dynamique : {str(erreur)}")
        
        # Ã‰tape 4 : Ã‰chec complet
        raise Exception(
            "Impossible d'initialiser un modÃ¨le Gemini. "
            "VÃ©rifiez votre clÃ© API et les permissions du projet."
        )

    def _decouvrir_modele_dynamiquement(self) -> Optional[genai.GenerativeModel]:
        """
        DÃ©couvre automatiquement un modÃ¨le disponible via l'API Gemini.
        
        StratÃ©gie de sÃ©lection :
        1. Prendre le premier modÃ¨le contenant "flash" (rapide et Ã©conomique)
        2. Sinon prendre le premier contenant "pro" (plus puissant)
        3. Sinon prendre n'importe quel modÃ¨le Gemini disponible
        
        Returns:
            GenerativeModel initialisÃ© ou None si Ã©chec
        """
        try:
            # Liste tous les modÃ¨les disponibles
            modeles_disponibles = list(genai.list_models())
            
            if not modeles_disponibles:
                raise Exception("Aucun modÃ¨le trouvÃ© dans la liste")
            
            # Filtrer uniquement les modÃ¨les de gÃ©nÃ©ration (pas les embeddings)
            modeles_generatifs = [
                m for m in modeles_disponibles 
                if hasattr(m, 'name') and 'embed' not in m.name.lower()
            ]
            
            print(f"   ðŸ“‹ {len(modeles_generatifs)} modÃ¨le(s) gÃ©nÃ©ratif(s) trouvÃ©(s)")
            
            # Affiche les modÃ¨les trouvÃ©s pour debug
            for m in modeles_generatifs[:5]:
                print(f"      - {m.name}")
            
            # StratÃ©gie de sÃ©lection par prioritÃ©
            modele_choisi = None
            
            # PrioritÃ© 1 : Flash (rapide, Ã©conomique)
            for m in modeles_generatifs:
                if 'flash' in m.name.lower():
                    modele_choisi = m.name
                    break
            
            # PrioritÃ© 2 : Pro (plus puissant)
            if not modele_choisi:
                for m in modeles_generatifs:
                    if 'pro' in m.name.lower():
                        modele_choisi = m.name
                        break
            
            # PrioritÃ© 3 : N'importe quel modÃ¨le Gemini
            if not modele_choisi and modeles_generatifs:
                modele_choisi = modeles_generatifs[0].name
            
            if modele_choisi:
                self._nom_modele_effectif = modele_choisi
                print(f"   ðŸŽ¯ ModÃ¨le sÃ©lectionnÃ© : {modele_choisi}")
                return genai.GenerativeModel(modele_choisi)
            
            return None
            
        except Exception as erreur:
            print(f"   Erreur lors de la dÃ©couverte : {str(erreur)}")
            return None

    def generer_script_cold_call(
        self,
        prospect: Prospect,
        trigger: Trigger,
        langue: Language,
        ton: str = "professionnel"
    ) -> Script:
        """
        GÃ©nÃ¨re un script de cold call personnalisÃ© avec Gemini.
        
        Args:
            prospect: Informations sur le prospect
            trigger: Ã‰vÃ©nement dÃ©clencheur
            langue: Langue souhaitÃ©e pour le script
            ton: Ton de la conversation
            
        Returns:
            Script complet gÃ©nÃ©rÃ© par l'IA
            
        Raises:
            Exception: Si la gÃ©nÃ©ration Ã©choue
        """
        try:
            # RÃ©cupÃ©ration du modÃ¨le (avec lazy loading et dÃ©couverte dynamique)
            modele = self._get_model()
            
            # Construction du prompt
            prompt = self._construire_prompt(prospect, trigger, langue, ton)
            
            print(f"ðŸ“ GÃ©nÃ©ration du script avec {self._nom_modele_effectif}...")
            
            # GÃ©nÃ©ration avec Gemini
            reponse = modele.generate_content(
                prompt,
                generation_config=self.config_generation
            )
            
            # Parsing de la rÃ©ponse
            contenu_genere = reponse.text
            
            return self._parser_script(contenu_genere, langue)
            
        except Exception as erreur:
            raise Exception(
                f"Erreur lors de la gÃ©nÃ©ration du script avec Gemini : {str(erreur)}"
            )

    def detecter_langue_ideale(self, prospect: Prospect) -> Language:
        """
        DÃ©tecte la langue idÃ©ale pour contacter un prospect.
        Utilise Gemini pour analyser les indices (entreprise, secteur, notes)
        et dÃ©terminer la meilleure langue pour le cold call.
        
        Args:
            prospect: Informations du prospect
            
        Returns:
            Langue recommandÃ©e (FRENCH, ENGLISH, etc.)
        """
        try:
            modele = self._get_model()
            
            # Construction du contexte pour l'analyse
            contexte = f"""
            Analyse ce prospect et dÃ©termine la langue la plus appropriÃ©e pour un cold call professionnel.
            
            INFORMATIONS DU PROSPECT :
            - Nom : {prospect.nom_complet}
            - Entreprise : {prospect.entreprise}
            - Secteur : {prospect.secteur_activite or "Non spÃ©cifiÃ©"}
            """
            
            # Ajout des notes enrichies si disponibles
            if prospect.notes_enrichies and prospect.notes_enrichies.notes_brutes:
                contexte += f"\n- Notes : {prospect.notes_enrichies.notes_brutes[:500]}"
            
            contexte += """
            
            INSTRUCTIONS :
            RÃ©ponds UNIQUEMENT avec le code langue ISO Ã  2 lettres parmi :
            - "fr" pour franÃ§ais
            - "en" pour anglais  
            - "es" pour espagnol
            - "de" pour allemand
            - "it" pour italien
            
            RÃ¨gles de dÃ©cision :
            - Entreprise franÃ§aise ou nom franÃ§ais â†’ "fr"
            - Entreprise internationale/tech/saas â†’ "en" 
            - Entreprise allemande â†’ "de"
            - Indices gÃ©ographiques dans les notes
            - Langue des notes si rÃ©digÃ©es en franÃ§ais/anglais
            
            RÃ©ponds uniquement avec le code (ex: "fr" ou "en").
            """
            
            reponse = modele.generate_content(
                contexte,
                generation_config={"temperature": 0.1, "max_output_tokens": 10}
            )
            
            # Extraction du code langue
            texte_reponse = reponse.text.strip().lower()
            
            # Mapping des codes vers l'enum
            mapping_langues = {
                "fr": Language.FRENCH,
                "en": Language.ENGLISH,
                "es": Language.SPANISH,
                "de": Language.GERMAN,
                "it": Language.ITALIAN
            }
            
            # Cherche le code dans la rÃ©ponse
            for code, langue in mapping_langues.items():
                if code in texte_reponse:
                    return langue
            
            # DÃ©tection par dÃ©faut basÃ©e sur l'entreprise
            return self._detecter_langue_par_defaut(prospect)
            
        except Exception:
            # En cas d'erreur, utiliser la dÃ©tection par dÃ©faut
            return self._detecter_langue_par_defaut(prospect)

    def _detecter_langue_par_defaut(self, prospect: Prospect) -> Language:
        """
        DÃ©tection de langue par dÃ©faut basÃ©e sur des rÃ¨gles simples.
        
        Args:
            prospect: Prospect Ã  analyser
            
        Returns:
            Langue dÃ©tectÃ©e
        """
        entreprise_lower = prospect.entreprise.lower()
        nom_lower = prospect.nom_complet.lower()
        
        # Mots-clÃ©s franÃ§ais
        mots_fr = ["sas", "france", "paris", "lyon", "marseille", "bordeaux", "lille", 
                   "toulouse", "nantes", "strasbourg", "fr", "franÃ§ais"]
        
        # Mots-clÃ©s internationaux (anglais probable)
        mots_intl = ["inc", "corp", "llc", "ltd", "gmbh", "ag", "bv", "sl", "global", 
                     "international", "ai", "tech", "labs", "io", "app", "cloud"]
        
        # Mots-clÃ©s allemands
        mots_de = ["gmbh", "ag", "kg", "germany", "deutschland", "berlin", "munich"]
        
        # VÃ©rification
        for mot in mots_fr:
            if mot in entreprise_lower or mot in nom_lower:
                return Language.FRENCH
        
        for mot in mots_de:
            if mot in entreprise_lower or mot in nom_lower:
                return Language.GERMAN
                
        for mot in mots_intl:
            if mot in entreprise_lower or mot in nom_lower:
                return Language.ENGLISH
        
        # Par dÃ©faut : anglais pour le B2B international
        return Language.ENGLISH

    def _construire_prompt(
        self,
        prospect: Prospect,
        trigger: Trigger,
        langue: Language,
        ton: str
    ) -> str:
        """
        Construit le prompt pour la gÃ©nÃ©ration du script.
        Utilise les notes enrichies si disponibles pour ultra-personnalisation.
        
        Args:
            prospect: Informations du prospect
            trigger: Ã‰vÃ©nement dÃ©clencheur
            langue: Langue souhaitÃ©e
            ton: Ton du script
            
        Returns:
            Prompt formatÃ© pour Gemini
        """
        # RÃ©cupÃ©ration du nom du vendeur depuis la config
        from infrastructure.config import obtenir_configuration
        config = obtenir_configuration()
        nom_vendeur = config.utilisateur_nom
        
        # Mapping des langues pour le prompt
        langues_texte = {
            Language.FRENCH: "franÃ§ais",
            Language.ENGLISH: "anglais",
            Language.SPANISH: "espagnol",
            Language.GERMAN: "allemand",
            Language.ITALIAN: "italien"
        }
        
        nom_langue = langues_texte.get(langue, "franÃ§ais")
        
        # Toutes les informations du prospect depuis Notion
        titre_info = f"Titre/Poste : {prospect.titre}" if prospect.titre else ""
        taille_info = f"Taille entreprise : {prospect.taille}" if prospect.taille else ""
        statut_info = f"Statut pipeline : {prospect.statut}" if prospect.statut else ""
        secteur_info = f"Secteur : {prospect.secteur_activite}" if prospect.secteur_activite else ""
        
        # Construction du contexte enrichi depuis les notes Notion
        contexte_enrichi = ""
        if prospect.notes_enrichies:
            notes = prospect.notes_enrichies
            
            # LES NOTES BRUTES SONT LE PLUS IMPORTANT
            if notes.notes_brutes:
                contexte_enrichi += f"\nðŸ“ NOTES BRUTES DU PROSPECT (Ã  utiliser obligatoirement) :\n{notes.notes_brutes}\n"
            
            if notes.situation_actuelle:
                contexte_enrichi += f"\nðŸ“Š SITUATION ACTUELLE :\n{notes.situation_actuelle}\n"
            
            if notes.pain_points:
                contexte_enrichi += "\nðŸŽ¯ PAIN POINTS IDENTIFIÃ‰S :\n"
                for i, pain in enumerate(notes.pain_points, 1):
                    contexte_enrichi += f"{i}. {pain}\n"
            
            if notes.value_proposition:
                contexte_enrichi += f"\nðŸ’Ž ANGLES DE VALEUR :\n{notes.value_proposition}\n"
        
        # Contexte des notes - UTILISATION OBLIGATOIRE
        notes_context = ""
        if prospect.notes_enrichies and prospect.notes_enrichies.notes_brutes:
            notes = prospect.notes_enrichies.notes_brutes[:3000]  # Limite pour Ã©viter de dÃ©passer les tokens
            notes_context = f"""
ðŸš¨ CONTEXTE OBLIGATOIRE - NOTES NOTION DU PROSPECT :
{notes}
ðŸš¨ FIN DES NOTES - TU DOIS UTILISER CE CONTEXTE DANS LE SCRIPT
"""
        
        prompt = f"""
Tu es un expert en vente B2B. GÃ©nÃ¨re un script de cold call ULTRA-PERSONNALISÃ‰ en {nom_langue} avec un ton {ton}.

========================================
TON IDENTITÃ‰
========================================
- Ton nom : {nom_vendeur}
- Ton entreprise : Gradium

========================================
INFORMATIONS DU PROSPECT
========================================
- Nom : {prospect.nom_complet}
- Entreprise : {prospect.entreprise}
{titre_info}
{taille_info}
{secteur_info}
{statut_info}

{notes_context}

========================================
TRIGGER
========================================
- Type : {trigger.type_trigger}
- Description : {trigger.description}

========================================
INSTRUCTIONS CRITIQUES
========================================

ðŸŽ¯ OBJECTIF : CrÃ©er un script qui montre que tu as fait tes recherches sur le prospect et qui gÃ©nÃ¨re un RDV.

ðŸŒ LANGUE : 100% DU SCRIPT DOIT ÃŠTRE EN {nom_langue.upper()} :
- Introduction en {nom_langue}
- Corps du message en {nom_langue}
- Proposition de valeur en {nom_langue}
- Call-to-action en {nom_langue}
- AUCUNE phrase dans une autre langue

âš ï¸ RÃˆGLES ABSOLUES :
1. Utilise IMPÃ‰RATIVEMENT les informations des NOTES NOTION ci-dessus
2. Mentionne des Ã©lÃ©ments spÃ©cifiques trouvÃ©s dans les notes (Hyper-Recrutement, Pain Points, etc.)
3. Parle en {nom_langue} NATIF (pas de mots franÃ§ais si la langue est anglais)
4. Mentionne le prÃ©nom du prospect 2-3 fois
5. Sois conversationnel et direct
6. Signe-toi avec ton vrai nom : "{nom_vendeur}"

ðŸ“‹ STRUCTURE OBLIGATOIRE (60-90 secondes) :

SÃ‰PARATION STRICTE ENTRE CHAQUE SECTION AVEC UNE LIGNE VIDE.

1. INTRODUCTION (10-15s)
   "Hi [PrÃ©nom], {nom_vendeur} here from Gradium..."
   â†’ Accroche personnalisÃ©e avec contexte des notes
   â†’ STOP - LIGNE VIDE OBLIGATOIRE APRÃˆS

2. CORPS DU MESSAGE (20-30s)
   â†’ Relie le trigger Ã  un problÃ¨me concret mentionnÃ© dans les notes
   â†’ Mentionne 1-2 dÃ©tails spÃ©cifiques des notes
   â†’ STOP - LIGNE VIDE OBLIGATOIRE APRÃˆS

3. PROPOSITION DE VALEUR (15-20s)
   â†’ Ã‰vite "With that kind of..." ou phrases gÃ©nÃ©riques
   â†’ Donne une proposition CONCRÃˆTE et CHIFFRÃ‰E si possible
   â†’ Exemple : "We help companies like [Entreprise] reduce ramp-up time by 40% through automated signal detection..."
   â†’ Explique COMMENT tu rÃ©sous le problÃ¨me
   â†’ STOP - LIGNE VIDE OBLIGATOIRE APRÃˆS

4. GESTION D'OBJECTION (10-15s)
   â†’ RÃ©ponse Ã  "I'm busy / Not interested / Already have a solution"
   â†’ STOP - LIGNE VIDE OBLIGATOIRE APRÃˆS

5. CALL-TO-ACTION (5-10s) STRICTEMENT EN {nom_langue.upper()}
   â†’ Si ANGLAIS : "Can we schedule a brief 15-minute call this week?" ou "Are you available for a quick call?"
   â†’ Si FRANÃ‡AIS : "Pouvons-nous convenir d'un appel rapide cette semaine ?"
   â†’ JAMAIS de mÃ©lange de langues dans le CTA

ðŸš« INTERDIT :
- Phrases gÃ©nÃ©riques comme "With that kind of..."
- MÃ©langer les langues dans le script
- Parler de soi plus que du prospect
- Oublier de signer avec son nom
- Ne pas utiliser les notes fournies
- Oublier les lignes vides entre les sections

âœ… FORMAT DE SORTIE EXACT :
1. [Texte introduction]

2. [Texte corps du message]

3. [Texte proposition de valeur]

4. [Texte gestion objection]

5. [Texte call-to-action EN {nom_langue.upper()}]
"""
        
        return prompt

    def _parser_script(self, contenu: str, langue: Language) -> Script:
        """Parse la rÃ©ponse de Gemini - Version simple et robuste."""
        import re
        
        contenu = contenu.strip()
        
        if not contenu:
            return Script(
                introduction="Hi, I'm calling about your company.",
                corps_message="I've noticed you're growing fast.",
                proposition_valeur="I can help you optimize your processes.",
                langue=langue
            )
        
        # DÃ©couper en blocs (sÃ©parÃ©s par ligne vide ou numÃ©ro de section)
        # Remplacer les numÃ©ros de section par des marqueurs
        contenu_clean = re.sub(r'\n?\s*(\d+)\.\s*', r'\n\nSECTION_\1\n\n', contenu)
        
        # DÃ©couper en paragraphes
        paragraphes = [p.strip() for p in contenu_clean.split('\n\n') if p.strip() and len(p.strip()) > 10]
        
        # Nettoyer les prÃ©fixes de section
        def nettoyer_bloc(texte):
            # Enlever les prÃ©fixes comme SECTION_1, INTRODUCTION, etc.
            texte = re.sub(r'^SECTION_\d+\s*', '', texte, flags=re.IGNORECASE)
            texte = re.sub(r'^(INTRODUCTION|CORPS|PROPOSITION|OBJECTION|CALL-TO-ACTION|CTA)[\s:]*', '', texte, flags=re.IGNORECASE)
            return texte.strip()
        
        # Assigner les paragraphes aux sections
        introduction = nettoyer_bloc(paragraphes[0]) if len(paragraphes) > 0 else ""
        corps_message = nettoyer_bloc(paragraphes[1]) if len(paragraphes) > 1 else ""
        proposition_valeur = nettoyer_bloc(paragraphes[2]) if len(paragraphes) > 2 else ""
        objection_text = nettoyer_bloc(paragraphes[3]) if len(paragraphes) > 3 else ""
        call_to_action = nettoyer_bloc(paragraphes[-1]) if len(paragraphes) > 4 else ""
        
        # Fallback si sections vides - prendre tout le contenu
        if not introduction:
            lines = contenu.split('\n')
            introduction = lines[0] if lines else ""
        
        # Valeurs par dÃ©faut si toujours vide
        if not introduction:
            introduction = "Hi, I'm calling about your company."
        if not corps_message:
            corps_message = "I've noticed some interesting developments at your company."
        if not proposition_valeur:
            proposition_valeur = "I believe we can help you achieve better results."
        if not call_to_action:
            # CTA dans la bonne langue
            if langue == Language.FRENCH:
                call_to_action = "Pouvons-nous convenir d'un appel de 15 minutes cette semaine ?"
            elif langue == Language.SPANISH:
                call_to_action = "Â¿Podemos programar una breve llamada esta semana?"
            elif langue == Language.GERMAN:
                call_to_action = "KÃ¶nnen wir diese Woche einen kurzen Anruf vereinbaren?"
            elif langue == Language.ITALIAN:
                call_to_action = "Possiamo organizzare una breve chiamata questa settimana?"
            else:  # ENGLISH par dÃ©faut
                call_to_action = "Can we schedule a brief 15-minute call this week?"
        
        objection_handling = [objection_text] if objection_text else []
        
        return Script(
            introduction=introduction,
            corps_message=corps_message,
            proposition_valeur=proposition_valeur,
            objection_handling=objection_handling,
            call_to_action=call_to_action,
            langue=langue,
            duree_estimee=75
        )


