"""
Client pour l'API Gemini (Google AI) avec dÃ©couverte dynamique des modÃ¨les.
ImplÃ©mente le port LLMProvider dÃ©fini dans le domaine.
Utilise le pattern "Dynamic Discovery" pour Ã©viter les erreurs 404.
"""

import re
from typing import Optional

import google.generativeai as genai

from domain.models import Prospect, Trigger, Script, Language
from domain.ports import LLMProvider
from infrastructure.config import obtenir_configuration


class GeminiClient(LLMProvider):
    """
    Adaptateur pour le modÃ¨le de langage Gemini de Google.
    ImplÃ©mente une dÃ©couverte dynamique des modÃ¨les pour Ã©viter les erreurs 404.
    """

    def __init__(
        self,
        cle_api: Optional[str] = None,
        nom_modele: Optional[str] = None
    ):
        """
        Initialise le client Gemini avec configuration minimale.
        Le modÃ¨le n'est pas configurÃ© ici (lazy loading).
        
        Args:
            cle_api: ClÃ© API Gemini (si None, utilise la config)
            nom_modele: Nom du modÃ¨le prÃ©fÃ©rÃ© (si None, utilise la config)
        """
        config = obtenir_configuration()
        self.cle_api = cle_api or config.gemini_cle_api
        self.nom_modele_preference = nom_modele or config.gemini_modele
        
        # Configuration de l'API Gemini (sans modÃ¨le spÃ©cifique)
        genai.configure(api_key=self.cle_api)
        
        # Le modÃ¨le sera initialisÃ© Ã  la demande (lazy loading)
        self._modele: Optional[genai.GenerativeModel] = None
        self._nom_modele_effectif: Optional[str] = None
        
        # Configuration de la gÃ©nÃ©ration (indÃ©pendante du modÃ¨le)
        self.config_generation = {
            "temperature": 0.7,
            "top_p": 0.95,
            "top_k": 40,
            "max_output_tokens": 8192,  
        }

    def _get_model(self) -> genai.GenerativeModel:
        """
        Lazy loading du modÃ¨le Gemini avec dÃ©couverte dynamique.
        Si le modÃ¨le n'est pas encore initialisÃ©, tente de le dÃ©couvrir automatiquement.
        
        Returns:
            Instance de GenerativeModel prÃªte Ã  l'emploi
            
        Raises:
            Exception: Si aucun modÃ¨le ne peut Ãªtre trouvÃ©
        """
        # Si dÃ©jÃ  initialisÃ©, retourne le modÃ¨le en cache
        if self._modele is not None:
            return self._modele
        
        print(f"ðŸ¤– Initialisation dynamique du modÃ¨le Gemini...")
        print(f"   PrÃ©fÃ©rence utilisateur : {self.nom_modele_preference}")
        
        # Ã‰tape 1 : Essayer le modÃ¨le prÃ©fÃ©rÃ© (s'il est spÃ©cifiÃ©)
        if self.nom_modele_preference:
            try:
                print(f"   Tentative avec : {self.nom_modele_preference}")
                modele = genai.GenerativeModel(self.nom_modele_preference)
                # Test rapide pour vÃ©rifier que le modÃ¨le existe
                modele._model_id  # AccÃ¨de Ã  l'ID pour valider
                self._modele = modele
                self._nom_modele_effectif = self.nom_modele_preference
                print(f"âœ… ModÃ¨le '{self._nom_modele_effectif}' chargÃ© avec succÃ¨s")
                return self._modele
            except Exception as erreur:
                print(f"   âš ï¸  Ã‰chec avec '{self.nom_modele_preference}' : {str(erreur)[:100]}")
        
        # Ã‰tape 2 : Liste des noms Ã  tester (ordre de prÃ©fÃ©rence)
        candidats_a_tester = [
            "gemini-1.5-flash-latest",
            "gemini-1.5-flash",
            "gemini-1.5-flash-001",
            "gemini-1.5-pro-latest",
            "gemini-1.5-pro",
            "gemini-1.5-pro-001",
            "gemini-1.0-pro-latest",
            "gemini-1.0-pro",
            "gemini-pro",
        ]
        
        for nom_candidat in candidats_a_tester:
            if nom_candidat == self.nom_modele_preference:
                continue  # DÃ©jÃ  testÃ© ci-dessus
            try:
                print(f"   Tentative avec : {nom_candidat}")
                modele = genai.GenerativeModel(nom_candidat)
                modele._model_id  # Validation
                self._modele = modele
                self._nom_modele_effectif = nom_candidat
                print(f"âœ… ModÃ¨le '{self._nom_modele_effectif}' chargÃ© avec succÃ¨s")
                return self._modele
            except Exception:
                continue  # Essayer le suivant
        
        # Ã‰tape 3 : DÃ©couverte dynamique via l'API
        print(f"   ðŸ” DÃ©couverte dynamique via list_models()...")
        try:
            modele_trouve = self._decouvrir_modele_dynamiquement()
            if modele_trouve:
                self._modele = modele_trouve
                print(f"âœ… ModÃ¨le dÃ©couvert dynamiquement : '{self._nom_modele_effectif}'")
                return self._modele
        except Exception as erreur:
            print(f"   âŒ Ã‰chec de la dÃ©couverte dynamique : {str(erreur)}")
        
        # Ã‰tape 4 : Ã‰chec complet
        raise Exception(
            "Impossible d'initialiser un modÃ¨le Gemini. "
            "VÃ©rifiez votre clÃ© API et les permissions du projet."
        )

    def _decouvrir_modele_dynamiquement(self) -> Optional[genai.GenerativeModel]:
        """
        DÃ©couvre automatiquement un modÃ¨le disponible via l'API Gemini.
        
        StratÃ©gie de sÃ©lection :
        1. Prendre le premier modÃ¨le contenant "flash" (rapide et Ã©conomique)
        2. Sinon prendre le premier contenant "pro" (plus puissant)
        3. Sinon prendre n'importe quel modÃ¨le Gemini disponible
        
        Returns:
            GenerativeModel initialisÃ© ou None si Ã©chec
        """
        try:
            # Liste tous les modÃ¨les disponibles
            modeles_disponibles = list(genai.list_models())
            
            if not modeles_disponibles:
                raise Exception("Aucun modÃ¨le trouvÃ© dans la liste")
            
            # Filtrer uniquement les modÃ¨les de gÃ©nÃ©ration (pas les embeddings)
            modeles_generatifs = [
                m for m in modeles_disponibles 
                if hasattr(m, 'name') and 'embed' not in m.name.lower()
            ]
            
            print(f"   ðŸ“‹ {len(modeles_generatifs)} modÃ¨le(s) gÃ©nÃ©ratif(s) trouvÃ©(s)")
            
            # Affiche les modÃ¨les trouvÃ©s pour debug
            for m in modeles_generatifs[:5]:
                print(f"      - {m.name}")
            
            # StratÃ©gie de sÃ©lection par prioritÃ©
            modele_choisi = None
            
            # PrioritÃ© 1 : Flash (rapide, Ã©conomique)
            for m in modeles_generatifs:
                if 'flash' in m.name.lower():
                    modele_choisi = m.name
                    break
            
            # PrioritÃ© 2 : Pro (plus puissant)
            if not modele_choisi:
                for m in modeles_generatifs:
                    if 'pro' in m.name.lower():
                        modele_choisi = m.name
                        break
            
            # PrioritÃ© 3 : N'importe quel modÃ¨le Gemini
            if not modele_choisi and modeles_generatifs:
                modele_choisi = modeles_generatifs[0].name
            
            if modele_choisi:
                self._nom_modele_effectif = modele_choisi
                print(f"   ðŸŽ¯ ModÃ¨le sÃ©lectionnÃ© : {modele_choisi}")
                return genai.GenerativeModel(modele_choisi)
            
            return None
            
        except Exception as erreur:
            print(f"   Erreur lors de la dÃ©couverte : {str(erreur)}")
            return None

    def generer_script_cold_call(
        self,
        prospect: Prospect,
        trigger: Trigger,
        langue: Language,
        ton: str = "professionnel"
    ) -> Script:
        """
        GÃ©nÃ¨re un script de cold call personnalisÃ© avec Gemini.
        
        Args:
            prospect: Informations sur le prospect
            trigger: Ã‰vÃ©nement dÃ©clencheur
            langue: Langue souhaitÃ©e pour le script
            ton: Ton de la conversation
            
        Returns:
            Script complet gÃ©nÃ©rÃ© par l'IA
            
        Raises:
            Exception: Si la gÃ©nÃ©ration Ã©choue
        """
        try:
            # RÃ©cupÃ©ration du modÃ¨le (avec lazy loading et dÃ©couverte dynamique)
            modele = self._get_model()
            
            # Construction du prompt
            prompt = self._construire_prompt(prospect, trigger, langue, ton)
            
            print(f"ðŸ“ GÃ©nÃ©ration du script avec {self._nom_modele_effectif}...")
            
            # GÃ©nÃ©ration avec Gemini
            reponse = modele.generate_content(
                prompt,
                generation_config=self.config_generation
            )
            
            # Retourner le texte brut sans parsing
            contenu_genere = reponse.text.strip()
            
            # Si le contenu est vide, retourner un script par dÃ©faut
            if not contenu_genere:
                return Script(
                    introduction="",
                    corps_message="Script non gÃ©nÃ©rÃ©. Veuillez rÃ©essayer.",
                    proposition_valeur="",
                    langue=langue
                )
            
            # Retourner tout le texte dans corps_message, sans parsing
            return Script(
                introduction="",
                corps_message=contenu_genere,
                proposition_valeur="",
                langue=langue,
                duree_estimee=60
            )
            
        except Exception as erreur:
            raise Exception(
                f"Erreur lors de la gÃ©nÃ©ration du script avec Gemini : {str(erreur)}"
            )

    def detecter_langue_ideale(self, prospect: Prospect) -> Language:
        """
        DÃ©tecte la langue idÃ©ale pour contacter un prospect.
        PrioritÃ©: Colonne Notion > RÃ¨gles > DÃ©faut (FranÃ§ais)
        """
        # 1. PrioritÃ© Ã  la colonne Langue de Notion
        if prospect.langue:
            langue_notion = prospect.langue.upper().strip()
            if langue_notion in ['FR', 'FRENCH']:
                return Language.FRENCH
            elif langue_notion in ['UK', 'EN', 'ENGLISH', 'US']:
                return Language.ENGLISH
            elif langue_notion in ['ES', 'SPANISH']:
                return Language.SPANISH
            elif langue_notion in ['DE', 'GERMAN']:
                return Language.GERMAN
            elif langue_notion in ['IT', 'ITALIAN']:
                return Language.ITALIAN
        
        # 2. RÃ¨gles par dÃ©faut
        nom_lower = prospect.nom_complet.lower() if prospect.nom_complet else ""
        entreprise_lower = prospect.entreprise.lower() if prospect.entreprise else ""
        notes_lower = prospect.notes_enrichies.notes_brutes.lower() if prospect.notes_enrichies and prospect.notes_enrichies.notes_brutes else ""
        
        # Noms typiquement franÃ§ais
        prenoms_fr = ['marie', 'jean', 'pierre', 'constance', 'marine', 'sophie', 'julien', 'thomas', 'nicolas', 'alexandre', 'brahim']
        for prenom in prenoms_fr:
            if prenom in nom_lower:
                return Language.FRENCH
        
        # Indices dans les notes
        mots_fr = ['france', 'paris', 'lyon', 'marseille', 'euros', 'levee', 'fonds', 'startup francaise', 'francaise']
        for mot in mots_fr:
            if mot in notes_lower or mot in entreprise_lower:
                return Language.FRENCH
        
        # Mots anglais
        mots_en = ['inc', 'llc', 'corp', 'ltd', 'uk', 'usa', 'america', 'london', 'new york', 'san francisco']
        for mot in mots_en:
            if mot in notes_lower or mot in entreprise_lower:
                return Language.ENGLISH
        
        # Par dÃ©faut: FranÃ§ais (car Gradium est FR)
        return Language.FRENCH

    def _detecter_langue_par_defaut(self, prospect: Prospect) -> Language:
        """
        DÃ©tection de langue par dÃ©faut basÃ©e sur des rÃ¨gles simples.
        
        Args:
            prospect: Prospect Ã  analyser
            
        Returns:
            Langue dÃ©tectÃ©e
        """
        entreprise_lower = prospect.entreprise.lower()
        nom_lower = prospect.nom_complet.lower()
        
        # Mots-clÃ©s franÃ§ais
        mots_fr = ["sas", "france", "paris", "lyon", "marseille", "bordeaux", "lille", 
                   "toulouse", "nantes", "strasbourg", "fr", "franÃ§ais"]
        
        # Mots-clÃ©s internationaux (anglais probable)
        mots_intl = ["inc", "corp", "llc", "ltd", "gmbh", "ag", "bv", "sl", "global", 
                     "international", "ai", "tech", "labs", "io", "app", "cloud"]
        
        # Mots-clÃ©s allemands
        mots_de = ["gmbh", "ag", "kg", "germany", "deutschland", "berlin", "munich"]
        
        # VÃ©rification
        for mot in mots_fr:
            if mot in entreprise_lower or mot in nom_lower:
                return Language.FRENCH
        
        for mot in mots_de:
            if mot in entreprise_lower or mot in nom_lower:
                return Language.GERMAN
                
        for mot in mots_intl:
            if mot in entreprise_lower or mot in nom_lower:
                return Language.ENGLISH
        
        # Par dÃ©faut : anglais pour le B2B international
        return Language.ENGLISH

    def _construire_prompt(
        self,
        prospect: Prospect,
        trigger: Trigger,
        langue: Language,
        ton: str
    ) -> str:
        """
        Construit le prompt pour la gÃ©nÃ©ration du script.
        Utilise les notes enrichies si disponibles pour ultra-personnalisation.
        
        Args:
            prospect: Informations du prospect
            trigger: Ã‰vÃ©nement dÃ©clencheur
            langue: Langue souhaitÃ©e
            ton: Ton du script
            
        Returns:
            Prompt formatÃ© pour Gemini
        """
        # RÃ©cupÃ©ration du nom du vendeur depuis la config
        from infrastructure.config import obtenir_configuration
        config = obtenir_configuration()
        nom_vendeur = config.utilisateur_nom
        
        # Mapping des langues pour le prompt
        langues_texte = {
            Language.FRENCH: "franÃ§ais",
            Language.ENGLISH: "anglais",
            Language.SPANISH: "espagnol",
            Language.GERMAN: "allemand",
            Language.ITALIAN: "italien"
        }
        
        nom_langue = langues_texte.get(langue, "franÃ§ais")
        
        # Toutes les informations du prospect depuis Notion
        titre_info = f"Titre/Poste : {prospect.titre}" if prospect.titre else ""
        taille_info = f"Taille entreprise : {prospect.taille}" if prospect.taille else ""
        statut_info = f"Statut pipeline : {prospect.statut}" if prospect.statut else ""
        secteur_info = f"Secteur : {prospect.secteur_activite}" if prospect.secteur_activite else ""
        
        # Construction du contexte enrichi depuis les notes Notion
        contexte_enrichi = ""
        if prospect.notes_enrichies:
            notes = prospect.notes_enrichies
            
            # LES NOTES BRUTES SONT LE PLUS IMPORTANT
            if notes.notes_brutes:
                contexte_enrichi += f"\nðŸ“ NOTES BRUTES DU PROSPECT (Ã  utiliser obligatoirement) :\n{notes.notes_brutes}\n"
            
            if notes.situation_actuelle:
                contexte_enrichi += f"\nðŸ“Š SITUATION ACTUELLE :\n{notes.situation_actuelle}\n"
            
            if notes.pain_points:
                contexte_enrichi += "\nðŸŽ¯ PAIN POINTS IDENTIFIÃ‰S :\n"
                for i, pain in enumerate(notes.pain_points, 1):
                    contexte_enrichi += f"{i}. {pain}\n"
            
            if notes.value_proposition:
                contexte_enrichi += f"\nðŸ’Ž ANGLES DE VALEUR :\n{notes.value_proposition}\n"
        
        # Contexte des notes - UTILISATION OBLIGATOIRE
        notes_context = ""
        if prospect.notes_enrichies and prospect.notes_enrichies.notes_brutes:
            notes = prospect.notes_enrichies.notes_brutes[:3000]  # Limite pour Ã©viter de dÃ©passer les tokens
            notes_context = f"""
ðŸš¨ CONTEXTE OBLIGATOIRE - NOTES NOTION DU PROSPECT :
{notes}
ðŸš¨ FIN DES NOTES - TU DOIS UTILISER CE CONTEXTE DANS LE SCRIPT
"""
        
        prompt = f"""
Tu es Brahim Bouhadja, sales chez Gradium. Tu dois Ã©crire un cold call VENDEUR et PERCUTANT pour {prospect.nom_complet}.

========================================
QUI EST GRADIUM ? (Ã€ UTILISER DANS LE SCRIPT)
========================================
Gradium est une startup franÃ§aise qui dÃ©veloppe des Audio LLMs natifs. Notre techno:
- Des agents vocaux IA ultra-naturels avec latence quasi-nulle
- 10x moins chers qu'une Ã©quipe de BDR
- Pas des voice bots basiques - de vrais LLM vocaux avec Ã©motion et fluiditÃ©

EXEMPLE DE SCRIPT PERCUTANT (pour inspiration):
"C'est ton premier BDR qui ne dort jamais. Je suis le modÃ¨le Gradium v1. Je viens de qualifier 500 leads pendant que tu prenais ton cafÃ©, et j'ai dÃ©tectÃ© 12 opportunitÃ©s chaudes pour ton Ã©quipe.

J'ai coÃ»tÃ© 4$ ce matin. Un humain t'aurait coÃ»tÃ© 200$.

[PrÃ©nom], si je suis capable de te convaincre maintenant avec cette fluiditÃ© et cette latence nulle... imagine ce que je peux faire avec tes clients.

On me dÃ©ploie quand sur ton CRM ?"

OU CE STYLE :
"Bonjour [PrÃ©nom],

Je vois que vous scalez massivement l'Ã©quipe Sales pour distribuer [produit].

Le problÃ¨me des Ã©quipes BDR humaines, c'est qu'elles sont limitÃ©es par le nombre d'heures dans une journÃ©e. Le problÃ¨me des Voice Bots actuels, c'est la latence et le manque d'Ã©motion qui tuent la conversion.

Gradium est diffÃ©rent : Nous dÃ©veloppons des Audio LLMs natifs. RÃ©sultat : des interactions vocales ultra-rapides, naturelles et expressives, capables de qualifier vos leads aussi bien que vos meilleurs humains, mais Ã  l'Ã©chelle infinie.

Si vous cherchez Ã  ce que votre 'Outbound' soit aussi intelligent que votre modÃ¨le, on devrait se parler."

========================================
INFORMATIONS DU PROSPECT (OBLIGATOIRE - UTILISER CES DÃ‰TAILS)
========================================
- Nom : {prospect.nom_complet}
- Entreprise : {prospect.entreprise}
- Poste : {prospect.titre or 'Non spÃ©cifiÃ©'}
{notes_context}

========================================
TRIGGER
========================================
- Type : {trigger.type_trigger}
- Description : {trigger.description}

========================================
INSTRUCTIONS ABSOLUES
========================================

ðŸŽ¯ OBJECTIF : VENDRE Gradium. Pas Ãªtre sympa. VENDRE. Le prospect doit sentir l'urgence et l'opportunitÃ©.

â±ï¸ DURÃ‰E MAXIMALE : 1 MINUTE (60 secondes) - Pas plus long. Un cold call efficace est court et percutant.

ðŸŒ LANGUE : 100% EN {nom_langue.upper()} - INTERDICTION TOTALE DE MÃ‰LANGER LES LANGUES

âš ï¸ RÃˆGLES :
1. Commence directement par l'accroche - pas de "Bonjour, comment allez-vous"
2. Utilise les NOTES NOTION ci-dessus pour personnaliser
3. Sois direct, percutant, presque provocateur mais professionnel
4. Mentionne Gradium comme la solution ultime Ã  leur problÃ¨me de scale
5. CrÃ©e de l'urgence : "Pendant qu'on parle, vos concurrents..."
6. Le ton doit Ãªtre : confiant, expert, lÃ©gÃ¨rement provocateur

ðŸš« INTERDICTIONS ABSOLUES :
- "I believe we can help you achieve better results" â†’ NUL
- "With that kind of..." â†’ NUL
- "Nous sommes une entreprise qui..." â†’ NUL
- Parler de soi au lieu du prospect
- MÃ©langer franÃ§ais et anglais
- Utiliser un ton trop formel ou trop familier - Trouve le juste milieu percutant
- Utiliser des phrases gÃ©nÃ©riques sans personnalisation
- Faire un script trop long ou trop court - vise 50-60 secondes
- commencer par "(Le tÃ©lÃ©phone sonne, Constance dÃ©croche)"

âœ… FORMAT DE SORTIE :
Un script FLUIDE, NATUREL, sans numÃ©ros de section. Juste du texte qui se lit comme une vraie conversation tÃ©lÃ©phonique percutante. Le script doit faire 45-60 secondes Ã  l'oral.
"""
        
        return prompt

    def _parser_script(self, contenu: str, langue: Language) -> Script:
        """Parse la rÃ©ponse de Gemini - Version simple et robuste."""
        import re
        
        contenu = contenu.strip()
        
        if not contenu:
            return Script(
                introduction="Hi, I'm calling about your company.",
                corps_message="I've noticed you're growing fast.",
                proposition_valeur="I can help you optimize your processes.",
                langue=langue
            )
        
        # DÃ©couper en blocs (sÃ©parÃ©s par ligne vide ou numÃ©ro de section)
        # Remplacer les numÃ©ros de section par des marqueurs
        contenu_clean = re.sub(r'\n?\s*(\d+)\.\s*', r'\n\nSECTION_\1\n\n', contenu)
        
        # DÃ©couper en paragraphes
        paragraphes = [p.strip() for p in contenu_clean.split('\n\n') if p.strip() and len(p.strip()) > 10]
        
        # Nettoyer les prÃ©fixes de section
        def nettoyer_bloc(texte):
            # Enlever les prÃ©fixes comme SECTION_1, INTRODUCTION, etc.
            texte = re.sub(r'^SECTION_\d+\s*', '', texte, flags=re.IGNORECASE)
            texte = re.sub(r'^(INTRODUCTION|CORPS|PROPOSITION|OBJECTION|CALL-TO-ACTION|CTA)[\s:]*', '', texte, flags=re.IGNORECASE)
            return texte.strip()
        
        # Assigner les paragraphes aux sections
        introduction = nettoyer_bloc(paragraphes[0]) if len(paragraphes) > 0 else ""
        corps_message = nettoyer_bloc(paragraphes[1]) if len(paragraphes) > 1 else ""
        proposition_valeur = nettoyer_bloc(paragraphes[2]) if len(paragraphes) > 2 else ""
        objection_text = nettoyer_bloc(paragraphes[3]) if len(paragraphes) > 3 else ""
        call_to_action = nettoyer_bloc(paragraphes[-1]) if len(paragraphes) > 4 else ""
        
        # Fallback si sections vides - prendre tout le contenu
        if not introduction:
            lines = contenu.split('\n')
            introduction = lines[0] if lines else ""
        
        # Valeurs par dÃ©faut si toujours vide
        if not introduction:
            introduction = "Hi, I'm calling about your company."
        if not corps_message:
            corps_message = "I've noticed some interesting developments at your company."
        if not proposition_valeur:
            proposition_valeur = "I believe we can help you achieve better results."
        if not call_to_action:
            # CTA dans la bonne langue
            if langue == Language.FRENCH:
                call_to_action = "Pouvons-nous convenir d'un appel de 15 minutes cette semaine ?"
            elif langue == Language.SPANISH:
                call_to_action = "Â¿Podemos programar una breve llamada esta semana?"
            elif langue == Language.GERMAN:
                call_to_action = "KÃ¶nnen wir diese Woche einen kurzen Anruf vereinbaren?"
            elif langue == Language.ITALIAN:
                call_to_action = "Possiamo organizzare una breve chiamata questa settimana?"
            else:  # ENGLISH par dÃ©faut
                call_to_action = "Can we schedule a brief 15-minute call this week?"
        
        objection_handling = [objection_text] if objection_text else []
        
        return Script(
            introduction=introduction,
            corps_message=corps_message,
            proposition_valeur=proposition_valeur,
            objection_handling=objection_handling,
            call_to_action=call_to_action,
            langue=langue,
            duree_estimee=75
        )


