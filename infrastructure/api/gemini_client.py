"""
Client pour l'API Gemini (Google AI).
ImplÃ©mente le port LLMProvider dÃ©fini dans le domaine.
Le modÃ¨le est lu directement depuis GEMINI_MODELE dans le fichier .env.
"""

import re
from typing import Optional

import google.generativeai as genai

from domain.models import Prospect, Trigger, Script, Language
from domain.ports import LLMProvider
from infrastructure.config import obtenir_configuration


class GeminiClient(LLMProvider):
    """
    Adaptateur pour le modÃ¨le de langage Gemini de Google.
    Utilise le modÃ¨le spÃ©cifiÃ© dans GEMINI_MODELE (fichier .env).
    """

    def __init__(
        self,
        cle_api: Optional[str] = None,
        nom_modele: Optional[str] = None
    ):
        """
        Initialise le client Gemini avec configuration minimale.
        Le modÃ¨le n'est pas configurÃ© ici (lazy loading).
        
        Args:
            cle_api: ClÃ© API Gemini (si None, utilise la config)
            nom_modele: Nom du modÃ¨le prÃ©fÃ©rÃ© (si None, utilise la config)
        """
        config = obtenir_configuration()
        self.cle_api = cle_api or config.gemini_cle_api
        self.nom_modele_preference = nom_modele or config.gemini_modele
        
        # Configuration de l'API Gemini (sans modÃ¨le spÃ©cifique)
        genai.configure(api_key=self.cle_api)
        
        # Le modÃ¨le sera initialisÃ© Ã  la demande (lazy loading)
        self._modele: Optional[genai.GenerativeModel] = None
        self._nom_modele_effectif: Optional[str] = None
        
        # Configuration de la gÃ©nÃ©ration (indÃ©pendante du modÃ¨le)
        self.config_generation = {
            "temperature": 0.7,
            "top_p": 0.95,
            "top_k": 40,
            "max_output_tokens": 8192,  
        }

    def _get_model(self) -> genai.GenerativeModel:
        """
        Initialise le modÃ¨le Gemini depuis la config (.env).
        Utilise directement GEMINI_MODELE sans fallback.
        
        Returns:
            Instance de GenerativeModel prÃªte Ã  l'emploi
        """
        # Si dÃ©jÃ  initialisÃ©, retourne le modÃ¨le en cache
        if self._modele is not None:
            return self._modele
        
        # Recharger la config Ã  chaque fois pour prendre en compte les modifications du .env
        from infrastructure.config import obtenir_configuration
        config = obtenir_configuration()
        nom_modele = self.nom_modele_preference or config.gemini_modele
        
        print(f"ðŸ¤– ModÃ¨le Gemini (depuis .env): {nom_modele}")
        
        try:
            modele = genai.GenerativeModel(nom_modele)
            self._modele = modele
            self._nom_modele_effectif = nom_modele
            print(f"âœ… ModÃ¨le chargÃ©: {nom_modele}")
            return self._modele
        except Exception as erreur:
            raise Exception(
                f"âŒ Impossible de charger le modÃ¨le '{nom_modele}'.\n"
                f"Erreur: {str(erreur)[:200]}\n"
                f"VÃ©rifiez GEMINI_MODELE dans votre fichier .env"
            )

    def generer_script_cold_call(
        self,
        prospect: Prospect,
        trigger: Trigger,
        langue: Language,
        ton: str = "professionnel"
    ) -> Script:
        """
        GÃ©nÃ¨re un script de cold call personnalisÃ© avec Gemini.
        
        Args:
            prospect: Informations sur le prospect
            trigger: Ã‰vÃ©nement dÃ©clencheur
            langue: Langue souhaitÃ©e pour le script
            ton: Ton de la conversation
            
        Returns:
            Script complet gÃ©nÃ©rÃ© par l'IA
            
        Raises:
            Exception: Si la gÃ©nÃ©ration Ã©choue
        """
        try:
            # RÃ©cupÃ©ration du modÃ¨le (avec lazy loading et dÃ©couverte dynamique)
            modele = self._get_model()
            
            # Construction du prompt
            prompt = self._construire_prompt(prospect, trigger, langue, ton)
            
            print(f"ðŸ“ GÃ©nÃ©ration du script avec {self._nom_modele_effectif}...")
            
            # GÃ©nÃ©ration avec Gemini
            reponse = modele.generate_content(
                prompt,
                generation_config=self.config_generation
            )
            
            # Retourner le texte brut sans parsing
            contenu_genere = reponse.text.strip()
            
            # Si le contenu est vide, retourner un script par dÃ©faut
            if not contenu_genere:
                return Script(
                    introduction="",
                    corps_message="Script non gÃ©nÃ©rÃ©. Veuillez rÃ©essayer.",
                    proposition_valeur="",
                    langue=langue
                )
            
            # Retourner tout le texte dans corps_message, sans parsing
            return Script(
                introduction="",
                corps_message=contenu_genere,
                proposition_valeur="",
                langue=langue,
                duree_estimee=60
            )
            
        except Exception as erreur:
            erreur_str = str(erreur)
            # DÃ©tection du quota dÃ©passÃ© (erreur 429)
            if "429" in erreur_str or "quota" in erreur_str.lower() or "exceeded" in erreur_str.lower():
                config = obtenir_configuration()
                modele_actuel = config.gemini_modele
                raise Exception(
                    f"ðŸš« Quota Gemini dÃ©passÃ© !\n\n"
                    f"Le modÃ¨le '{modele_actuel}' a atteint sa limite quotidienne.\n"
                    f"Les quotas gratuits se rÃ©initialisent chaque jour.\n\n"
                    f"ðŸ’¡ Solutions :\n"
                    f"â€¢ Modifiez GEMINI_MODELE dans .env (ex: gemini-1.5-flash-latest)\n"
                    f"â€¢ Passez Ã  Kimi (LLM_PROVIDER=kimi)\n"
                    f"â€¢ RÃ©essayez demain (quotas rÃ©initialisÃ©s Ã  minuit UTC)"
                )
            raise Exception(
                f"Erreur lors de la gÃ©nÃ©ration du script avec Gemini : {erreur_str}"
            )

    def detecter_langue_ideale(self, prospect: Prospect) -> Language:
        """
        DÃ©tecte la langue idÃ©ale pour contacter un prospect.
        PrioritÃ©: Colonne Notion > RÃ¨gles > DÃ©faut (FranÃ§ais)
        """
        # 1. PrioritÃ© Ã  la colonne Langue de Notion
        if prospect.langue:
            langue_notion = prospect.langue.upper().strip()
            if langue_notion in ['FR', 'FRENCH']:
                return Language.FRENCH
            elif langue_notion in ['UK', 'EN', 'ENGLISH', 'US']:
                return Language.ENGLISH
            elif langue_notion in ['ES', 'SPANISH']:
                return Language.SPANISH
            elif langue_notion in ['DE', 'GERMAN']:
                return Language.GERMAN
            elif langue_notion in ['IT', 'ITALIAN']:
                return Language.ITALIAN
        
        # 2. RÃ¨gles par dÃ©faut
        nom_lower = prospect.nom_complet.lower() if prospect.nom_complet else ""
        entreprise_lower = prospect.entreprise.lower() if prospect.entreprise else ""
        notes_lower = prospect.notes_enrichies.notes_brutes.lower() if prospect.notes_enrichies and prospect.notes_enrichies.notes_brutes else ""
        
        # Noms typiquement franÃ§ais
        prenoms_fr = ['marie', 'jean', 'pierre', 'constance', 'marine', 'sophie', 'julien', 'thomas', 'nicolas', 'alexandre', 'brahim']
        for prenom in prenoms_fr:
            if prenom in nom_lower:
                return Language.FRENCH
        
        # Indices dans les notes
        mots_fr = ['france', 'paris', 'lyon', 'marseille', 'euros', 'levee', 'fonds', 'startup francaise', 'francaise']
        for mot in mots_fr:
            if mot in notes_lower or mot in entreprise_lower:
                return Language.FRENCH
        
        # Mots anglais
        mots_en = ['inc', 'llc', 'corp', 'ltd', 'uk', 'usa', 'america', 'london', 'new york', 'san francisco']
        for mot in mots_en:
            if mot in notes_lower or mot in entreprise_lower:
                return Language.ENGLISH
        
        # Par dÃ©faut: FranÃ§ais (car Gradium est FR)
        return Language.FRENCH

    def _detecter_langue_par_defaut(self, prospect: Prospect) -> Language:
        """
        DÃ©tection de langue par dÃ©faut basÃ©e sur des rÃ¨gles simples.
        
        Args:
            prospect: Prospect Ã  analyser
            
        Returns:
            Langue dÃ©tectÃ©e
        """
        entreprise_lower = prospect.entreprise.lower()
        nom_lower = prospect.nom_complet.lower()
        
        # Mots-clÃ©s franÃ§ais
        mots_fr = ["sas", "france", "paris", "lyon", "marseille", "bordeaux", "lille", 
                   "toulouse", "nantes", "strasbourg", "fr", "franÃ§ais"]
        
        # Mots-clÃ©s internationaux (anglais probable)
        mots_intl = ["inc", "corp", "llc", "ltd", "gmbh", "ag", "bv", "sl", "global", 
                     "international", "ai", "tech", "labs", "io", "app", "cloud"]
        
        # Mots-clÃ©s allemands
        mots_de = ["gmbh", "ag", "kg", "germany", "deutschland", "berlin", "munich"]
        
        # VÃ©rification
        for mot in mots_fr:
            if mot in entreprise_lower or mot in nom_lower:
                return Language.FRENCH
        
        for mot in mots_de:
            if mot in entreprise_lower or mot in nom_lower:
                return Language.GERMAN
                
        for mot in mots_intl:
            if mot in entreprise_lower or mot in nom_lower:
                return Language.ENGLISH
        
        # Par dÃ©faut : anglais pour le B2B international
        return Language.ENGLISH

    def _construire_prompt(
        self,
        prospect: Prospect,
        trigger: Trigger,
        langue: Language,
        ton: str
    ) -> str:
        """
        Construit le prompt pour la gÃ©nÃ©ration du script.
        Utilise les notes enrichies si disponibles pour ultra-personnalisation.
        
        Args:
            prospect: Informations du prospect
            trigger: Ã‰vÃ©nement dÃ©clencheur
            langue: Langue souhaitÃ©e
            ton: Ton du script
            
        Returns:
            Prompt formatÃ© pour Gemini
        """
        # RÃ©cupÃ©ration du nom du vendeur depuis la config
        from infrastructure.config import obtenir_configuration
        config = obtenir_configuration()
        nom_vendeur = config.utilisateur_nom
        
        # Mapping des langues pour le prompt
        langues_texte = {
            Language.FRENCH: "franÃ§ais",
            Language.ENGLISH: "anglais",
            Language.SPANISH: "espagnol",
            Language.GERMAN: "allemand",
            Language.ITALIAN: "italien"
        }
        
        nom_langue = langues_texte.get(langue, "franÃ§ais")
        
        # Toutes les informations du prospect depuis Notion
        titre_info = f"Titre/Poste : {prospect.titre}" if prospect.titre else ""
        taille_info = f"Taille entreprise : {prospect.taille}" if prospect.taille else ""
        statut_info = f"Statut pipeline : {prospect.statut}" if prospect.statut else ""
        secteur_info = f"Secteur : {prospect.secteur_activite}" if prospect.secteur_activite else ""
        
        # Construction du contexte enrichi depuis les notes Notion
        contexte_enrichi = ""
        if prospect.notes_enrichies:
            notes = prospect.notes_enrichies
            
            # LES NOTES BRUTES SONT LE PLUS IMPORTANT
            if notes.notes_brutes:
                contexte_enrichi += f"\nðŸ“ NOTES BRUTES DU PROSPECT (Ã  utiliser obligatoirement) :\n{notes.notes_brutes}\n"
            
            if notes.situation_actuelle:
                contexte_enrichi += f"\nðŸ“Š SITUATION ACTUELLE :\n{notes.situation_actuelle}\n"
            
            if notes.pain_points:
                contexte_enrichi += "\nðŸŽ¯ PAIN POINTS IDENTIFIÃ‰S :\n"
                for i, pain in enumerate(notes.pain_points, 1):
                    contexte_enrichi += f"{i}. {pain}\n"
            
            if notes.value_proposition:
                contexte_enrichi += f"\nðŸ’Ž ANGLES DE VALEUR :\n{notes.value_proposition}\n"
        
        # Contexte des notes - UTILISATION OBLIGATOIRE
        notes_context = ""
        if prospect.notes_enrichies and prospect.notes_enrichies.notes_brutes:
            notes = prospect.notes_enrichies.notes_brutes[:3000]  # Limite pour Ã©viter de dÃ©passer les tokens
            notes_context = f"""
ðŸš¨ CONTEXTE OBLIGATOIRE - NOTES NOTION DU PROSPECT :
{notes}
ðŸš¨ FIN DES NOTES - TU DOIS UTILISER CE CONTEXTE DANS LE SCRIPT
"""
        
        prompt = f"""
Tu es Brahim Bouhadja, sales chez Gradium. Tu dois Ã©crire un cold call VENDEUR et PERCUTANT pour {prospect.nom_complet}.

========================================
QUI EST GRADIUM ? (Ã€ UTILISER DANS LE SCRIPT)
========================================
Gradium est une startup franÃ§aise qui dÃ©veloppe des Audio LLMs natifs. Notre techno:
- Des agents vocaux IA ultra-naturels avec latence quasi-nulle
- 10x moins chers qu'une Ã©quipe de BDR
- Pas des voice bots basiques - de vrais LLM vocaux avec Ã©motion et fluiditÃ©

EXEMPLE DE SCRIPT PERCUTANT (pour inspiration):
"C'est ton premier BDR qui ne dort jamais. Je suis le modÃ¨le Gradium v1. Je viens de qualifier 500 leads pendant que tu prenais ton cafÃ©, et j'ai dÃ©tectÃ© 12 opportunitÃ©s chaudes pour ton Ã©quipe.

J'ai coÃ»tÃ© 4$ ce matin. Un humain t'aurait coÃ»tÃ© 200$.

[PrÃ©nom], si je suis capable de te convaincre maintenant avec cette fluiditÃ© et cette latence nulle... imagine ce que je peux faire avec tes clients.

On me dÃ©ploie quand sur ton CRM ?"

OU CE STYLE :
"Bonjour [PrÃ©nom],

Je vois que vous scalez massivement l'Ã©quipe Sales pour distribuer [produit].

Le problÃ¨me des Ã©quipes BDR humaines, c'est qu'elles sont limitÃ©es par le nombre d'heures dans une journÃ©e. Le problÃ¨me des Voice Bots actuels, c'est la latence et le manque d'Ã©motion qui tuent la conversion.

Gradium est diffÃ©rent : Nous dÃ©veloppons des Audio LLMs natifs. RÃ©sultat : des interactions vocales ultra-rapides, naturelles et expressives, capables de qualifier vos leads aussi bien que vos meilleurs humains, mais Ã  l'Ã©chelle infinie.

Si vous cherchez Ã  ce que votre 'Outbound' soit aussi intelligent que votre modÃ¨le, on devrait se parler."

========================================
INFORMATIONS DU PROSPECT (OBLIGATOIRE - UTILISER CES DÃ‰TAILS)
========================================
- Nom : {prospect.nom_complet}
- Entreprise : {prospect.entreprise}
- Poste : {prospect.titre or 'Non spÃ©cifiÃ©'}
{notes_context}

========================================
TRIGGER
========================================
- Type : {trigger.type_trigger}
- Description : {trigger.description}

========================================
INSTRUCTIONS ABSOLUES
========================================

ðŸŽ¯ OBJECTIF : VENDRE Gradium. Pas Ãªtre sympa. VENDRE. Le prospect doit sentir l'urgence et l'opportunitÃ©.

â±ï¸ DURÃ‰E MAXIMALE : 1 MINUTE (60 secondes) - Pas plus long. Un cold call efficace est court et percutant.

ðŸŒ LANGUE : 100% EN {nom_langue.upper()} - INTERDICTION TOTALE DE MÃ‰LANGER LES LANGUES

âš ï¸ RÃˆGLES :
1. Commence directement par l'accroche - pas de "Bonjour, comment allez-vous"
2. Utilise les NOTES NOTION ci-dessus pour personnaliser
3. Sois direct, percutant, presque provocateur mais professionnel
4. Mentionne Gradium comme la solution ultime Ã  leur problÃ¨me de scale
5. CrÃ©e de l'urgence : "Pendant qu'on parle, vos concurrents..."
6. Le ton doit Ãªtre : confiant, expert, lÃ©gÃ¨rement provocateur

ðŸš« INTERDICTIONS ABSOLUES :
- "I believe we can help you achieve better results" â†’ NUL
- "With that kind of..." â†’ NUL
- "Nous sommes une entreprise qui..." â†’ NUL
- Parler de soi au lieu du prospect
- MÃ©langer franÃ§ais et anglais
- Utiliser un ton trop formel ou trop familier - Trouve le juste milieu percutant
- Utiliser des phrases gÃ©nÃ©riques sans personnalisation
- Faire un script trop long ou trop court - vise 50-60 secondes
- commencer par "(Le tÃ©lÃ©phone sonne, Constance dÃ©croche)"

âœ… FORMAT DE SORTIE :
Un script FLUIDE, NATUREL, sans numÃ©ros de section. Juste du texte qui se lit comme une vraie conversation tÃ©lÃ©phonique percutante. Le script doit faire 45-60 secondes Ã  l'oral.
"""
        
        return prompt

    def _parser_script(self, contenu: str, langue: Language) -> Script:
        """Parse la rÃ©ponse de Gemini - Version simple et robuste."""
        import re
        
        contenu = contenu.strip()
        
        if not contenu:
            return Script(
                introduction="Hi, I'm calling about your company.",
                corps_message="I've noticed you're growing fast.",
                proposition_valeur="I can help you optimize your processes.",
                langue=langue
            )
        
        # DÃ©couper en blocs (sÃ©parÃ©s par ligne vide ou numÃ©ro de section)
        # Remplacer les numÃ©ros de section par des marqueurs
        contenu_clean = re.sub(r'\n?\s*(\d+)\.\s*', r'\n\nSECTION_\1\n\n', contenu)
        
        # DÃ©couper en paragraphes
        paragraphes = [p.strip() for p in contenu_clean.split('\n\n') if p.strip() and len(p.strip()) > 10]
        
        # Nettoyer les prÃ©fixes de section
        def nettoyer_bloc(texte):
            # Enlever les prÃ©fixes comme SECTION_1, INTRODUCTION, etc.
            texte = re.sub(r'^SECTION_\d+\s*', '', texte, flags=re.IGNORECASE)
            texte = re.sub(r'^(INTRODUCTION|CORPS|PROPOSITION|OBJECTION|CALL-TO-ACTION|CTA)[\s:]*', '', texte, flags=re.IGNORECASE)
            return texte.strip()
        
        # Assigner les paragraphes aux sections
        introduction = nettoyer_bloc(paragraphes[0]) if len(paragraphes) > 0 else ""
        corps_message = nettoyer_bloc(paragraphes[1]) if len(paragraphes) > 1 else ""
        proposition_valeur = nettoyer_bloc(paragraphes[2]) if len(paragraphes) > 2 else ""
        objection_text = nettoyer_bloc(paragraphes[3]) if len(paragraphes) > 3 else ""
        call_to_action = nettoyer_bloc(paragraphes[-1]) if len(paragraphes) > 4 else ""
        
        # Fallback si sections vides - prendre tout le contenu
        if not introduction:
            lines = contenu.split('\n')
            introduction = lines[0] if lines else ""
        
        # Valeurs par dÃ©faut si toujours vide
        if not introduction:
            introduction = "Hi, I'm calling about your company."
        if not corps_message:
            corps_message = "I've noticed some interesting developments at your company."
        if not proposition_valeur:
            proposition_valeur = "I believe we can help you achieve better results."
        if not call_to_action:
            # CTA dans la bonne langue
            if langue == Language.FRENCH:
                call_to_action = "Pouvons-nous convenir d'un appel de 15 minutes cette semaine ?"
            elif langue == Language.SPANISH:
                call_to_action = "Â¿Podemos programar una breve llamada esta semana?"
            elif langue == Language.GERMAN:
                call_to_action = "KÃ¶nnen wir diese Woche einen kurzen Anruf vereinbaren?"
            elif langue == Language.ITALIAN:
                call_to_action = "Possiamo organizzare una breve chiamata questa settimana?"
            else:  # ENGLISH par dÃ©faut
                call_to_action = "Can we schedule a brief 15-minute call this week?"
        
        objection_handling = [objection_text] if objection_text else []
        
        return Script(
            introduction=introduction,
            corps_message=corps_message,
            proposition_valeur=proposition_valeur,
            objection_handling=objection_handling,
            call_to_action=call_to_action,
            langue=langue,
            duree_estimee=75
        )


